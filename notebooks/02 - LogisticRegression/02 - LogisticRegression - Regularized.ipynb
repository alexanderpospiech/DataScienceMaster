{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Logistic Regression</a></div><div class=\"lev2 toc-item\"><a href=\"#My-notes:\" data-toc-modified-id=\"My-notes:-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>My notes:</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-and-Inspect-the-Data\" data-toc-modified-id=\"Load-and-Inspect-the-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load and Inspect the Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Which-dimensions-to-choose-for-the-prediction?\" data-toc-modified-id=\"Which-dimensions-to-choose-for-the-prediction?-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Which dimensions to choose for the prediction?</a></div><div class=\"lev1 toc-item\"><a href=\"#Data-Preparation-(train,-test)\" data-toc-modified-id=\"Data-Preparation-(train,-test)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preparation (train, test)</a></div><div class=\"lev1 toc-item\"><a href=\"#Manual-Implementation\" data-toc-modified-id=\"Manual-Implementation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Manual Implementation</a></div><div class=\"lev2 toc-item\"><a href=\"#Algorithm\" data-toc-modified-id=\"Algorithm-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Algorithm</a></div><div class=\"lev2 toc-item\"><a href=\"#Experiment\" data-toc-modified-id=\"Experiment-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Experiment</a></div><div class=\"lev2 toc-item\"><a href=\"#Analysis-of-parameters\" data-toc-modified-id=\"Analysis-of-parameters-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Analysis of parameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Analysis-of-Convergence\" data-toc-modified-id=\"Analysis-of-Convergence-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Analysis of Convergence</a></div><div class=\"lev1 toc-item\"><a href=\"#Library-Implementations\" data-toc-modified-id=\"Library-Implementations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Library Implementations</a></div><div class=\"lev2 toc-item\"><a href=\"#Statsmodel\" data-toc-modified-id=\"Statsmodel-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Statsmodel</a></div><div class=\"lev2 toc-item\"><a href=\"#SKLearn\" data-toc-modified-id=\"SKLearn-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>SKLearn</a></div><div class=\"lev2 toc-item\"><a href=\"#SciPy\" data-toc-modified-id=\"SciPy-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>SciPy</a></div><div class=\"lev1 toc-item\"><a href=\"#Sources:\" data-toc-modified-id=\"Sources:-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Sources:</a></div><div class=\"lev2 toc-item\"><a href=\"#Overviews:\" data-toc-modified-id=\"Overviews:-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Overviews:</a></div><div class=\"lev2 toc-item\"><a href=\"#Notebooks:\" data-toc-modified-id=\"Notebooks:-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Notebooks:</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## My notes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiments we will use the heart disease dataset (https://archive.ics.uci.edu/ml/datasets/heart+Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('./data/heart-disease.csv')\n",
    "df['num_norm'] = df['num']\n",
    "df['num_norm'] = df['num'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "# remove rows with NA values\n",
    "df = df[(df['ca'] != '?') & (df['thal'] != '?')]\n",
    "\n",
    "# transform nominal categorical columns into dummy variables\n",
    "df = pd.concat([df, pd.get_dummies(df['cp'], prefix = 'cp')], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['restecg'], prefix = 'restecg')], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['slope'], prefix = 'slope')], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['thal'], prefix = 'thal')], axis=1)\n",
    "\n",
    "value_columns = list(df)\n",
    "value_columns.remove('num_norm')\n",
    "value_columns.remove('num')\n",
    "\n",
    "columns = list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which dimensions to choose for the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [01 - LogisticRegression - MultiVariate.ipynb](01 - LogisticRegression - MultiVariate.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the RandomizedLasso:\n",
      "[(0.51500000000000001, 'cp_2.0'), (0.48999999999999999, 'ca'), (0.44, 'thal'), (0.33500000000000002, 'slope_2.0'), (0.26000000000000001, 'thalach'), (0.25, 'exang'), (0.23999999999999999, 'oldpeak'), (0.13, 'thal_3.0'), (0.13, 'cp'), (0.065000000000000002, 'restecg_1.0'), (0.01, 'slope'), (0.0050000000000000001, 'sex'), (0.0050000000000000001, 'cp_1.0'), (0.0, 'trestbps'), (0.0, 'slope_3.0'), (0.0, 'slope_1.0'), (0.0, 'restecg_2.0'), (0.0, 'restecg_0.0'), (0.0, 'restecg'), (0.0, 'num_norm'), (0.0, 'num'), (0.0, 'fbs'), (0.0, 'cp_4.0'), (0.0, 'cp_3.0'), (0.0, 'chol'), (0.0, 'age')]\n",
      "\n",
      "Columns with a score >0.1\n",
      "['cp_2.0', 'ca', 'thal', 'slope_2.0', 'thalach', 'exang', 'oldpeak', 'thal_3.0', 'cp']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.01)\n",
    "rlasso.fit(df[value_columns], df[['num_norm']].values.ravel())\n",
    "\n",
    "stable_columns = sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), columns), reverse=True)\n",
    "print('The result of the RandomizedLasso:')\n",
    "print(stable_columns)\n",
    "\n",
    "print()\n",
    "print('Columns with a score >0.1')\n",
    "stable_columns = [x[1] for x in stable_columns if x[0] > 0.1]\n",
    "print(stable_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'thal_3.0'), (2, 'exang'), (3, 'restecg_1.0'), (4, 'ca'), (5, 'cp_1.0'), (6, 'cp_4.0'), (7, 'sex'), (8, 'cp'), (9, 'slope_3.0'), (10, 'cp_3.0'), (11, 'thal'), (12, 'restecg_2.0'), (13, 'oldpeak'), (14, 'fbs'), (15, 'restecg_0.0'), (16, 'restecg'), (17, 'cp_2.0'), (18, 'num_norm'), (19, 'slope_1.0'), (20, 'slope'), (21, 'num'), (22, 'trestbps'), (23, 'slope_2.0'), (24, 'thalach'), (25, 'age'), (26, 'chol')]\n",
      "The result of the LinearRegression:\n",
      "\n",
      "Columns with a score <5\n",
      "['thal_3.0', 'exang', 'restecg_1.0', 'ca']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(df[value_columns], df[['num_norm']].values.ravel())\n",
    "\n",
    "rfe_columns = sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), columns))\n",
    "print(rfe_columns)\n",
    "print('The result of the LinearRegression:')\n",
    "\n",
    "print()\n",
    "print('Columns with a score <5')\n",
    "rfe_columns = [x[1] for x in rfe_columns if x[0] < 5]\n",
    "print(rfe_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do our expirements on three different subsets of the data. So we will see the impact of the choose of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt, zeros, ones, array, linspace, logspace, vstack\n",
    "\n",
    "# Xs\n",
    "X = df[value_columns]\n",
    "X_stable= df[stable_columns]\n",
    "X_rfe= df[rfe_columns]\n",
    "# Y\n",
    "y_norm = df[\"num_norm\"]\n",
    "y = df['num']\n",
    "\n",
    "# number of entries\n",
    "n = y.size \n",
    "# Add a column of ones to X (interception data)\n",
    "it = ones(shape=(n, len(list(X))+1 ) )\n",
    "it[:, 1:] = X\n",
    "X = it\n",
    "it = ones(shape=(n, len(list(X_stable))+1 ) )\n",
    "it[:, 1:] = X_stable\n",
    "X_stable = it\n",
    "it = ones(shape=(n, len(list(X_rfe))+1 ) )\n",
    "it[:, 1:] = X_rfe\n",
    "X_rfe = it\n",
    "\n",
    "# Create a mask for selecting randomly 20% of data\n",
    "msk = np.random.rand(len(y)) < 0.2\n",
    "\n",
    "# Split x-values for into train and test datasets\n",
    "X_test = X[msk]\n",
    "X = X[~msk]\n",
    "X_stable_test = X_stable[msk]\n",
    "X_stable = X_stable[~msk]\n",
    "X_rfe_test = X_rfe[msk]\n",
    "X_rfe = X_rfe[~msk]\n",
    "\n",
    "# Split y-values for media_value into train and test data\n",
    "y_test = y[msk].copy()\n",
    "y = y[~msk].copy()\n",
    "y_norm_test = y_norm[msk].copy()\n",
    "y_norm = y_norm[~msk].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to jdwittenauer for his implementation of logistic regression. \n",
    "\n",
    "https://nbviewer.jupyter.org/github/jdwittenauer/ipython-notebooks/blob/master/notebooks/ml/ML-Exercise2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function, which represents the propability of being 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAB8CAYAAADzTYXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f989b9eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nums = np.arange(-10, 10, step=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,1))\n",
    "a = ax.plot(nums, sigmoid(nums), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(theta, X, y, regularized=False, learning_rate=1):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    if regularized:\n",
    "        reg = (learning_rate / 2 * len(X)) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "        return np.sum(first - second) / (len(X)) + reg\n",
    "    else:\n",
    "        return np.sum(first - second) / (len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill theta with zeros as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(X.shape[1])\n",
    "theta_stable= np.zeros(X_stable.shape[1])\n",
    "theta_rfe = np.zeros(X_rfe.shape[1])\n",
    "\n",
    "#theta = 0.1* np.random.randn(X.shape[1])\n",
    "#theta_stable = 0.1* np.random.randn(X_stable.shape[1])\n",
    "#theta_rfe = 0.1* np.random.randn(X_rfe.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The costs for an unoptimized theta and the three different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n",
      "173.28679514\n"
     ]
    }
   ],
   "source": [
    "print(cost(theta, X, y_norm))\n",
    "print(cost(theta, X, y_norm, True))\n",
    "\n",
    "print(cost(theta_stable, X_stable, y_norm))\n",
    "print(cost(theta_stable, X_stable, y_norm, True))\n",
    "\n",
    "print(cost(theta_rfe, X_rfe, y_norm))\n",
    "print(cost(theta_rfe, X_rfe, y_norm, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithm for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, regularized=False, learning_rate=1):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "    \n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "        if (regularized == False or i == 0):\n",
    "            grad[i] = np.sum(term) / len(X)\n",
    "        else:\n",
    "            grad[i] = (np.sum(term) / len(X)) + ((learning_rate / len(X)) * theta[:,i])\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thetas after the first round of applying the gradient descent algorithm on the three different subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.00000000e+00   2.74280000e+02   3.44000000e+00   1.58800000e+01\n",
      "   6.61860000e+02   1.23676000e+03   7.40000000e-01   4.82000000e+00\n",
      "   7.48100000e+02   1.66000000e+00   5.38200000e+00   8.02000000e+00\n",
      "   3.52000000e+00   2.41600000e+01   3.60000000e-01   8.20000000e-01\n",
      "   1.40000000e+00   2.42000000e+00   2.56000000e+00   6.00000000e-02\n",
      "   2.38000000e+00   2.32000000e+00   2.34000000e+00   3.40000000e-01\n",
      "   2.62000000e+00   3.60000000e-01   2.02000000e+00]\n",
      "[  5.00000000e+00   2.74280000e+02   3.44000000e+00   1.58800000e+01\n",
      "   6.61860000e+02   1.23676000e+03   7.40000000e-01   4.82000000e+00\n",
      "   7.48100000e+02   1.66000000e+00   5.38200000e+00   8.02000000e+00\n",
      "   3.52000000e+00   2.41600000e+01   3.60000000e-01   8.20000000e-01\n",
      "   1.40000000e+00   2.42000000e+00   2.56000000e+00   6.00000000e-02\n",
      "   2.38000000e+00   2.32000000e+00   2.34000000e+00   3.40000000e-01\n",
      "   2.62000000e+00   3.60000000e-01   2.02000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(gradient(theta, X, y_norm))\n",
    "print(gradient(theta, X, y_norm, regularized=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   5.       0.82     3.52    24.16     2.34   748.1      1.66     5.382\n",
      "    2.62    15.88 ]\n",
      "[   5.       0.82     3.52    24.16     2.34   748.1      1.66     5.382\n",
      "    2.62    15.88 ]\n"
     ]
    }
   ],
   "source": [
    "print(gradient(theta_stable, X_stable, y_norm))\n",
    "print(gradient(theta_stable, X_stable, y_norm, regularized=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.    2.62  1.66  0.06  3.52]\n",
      "[ 5.    2.62  1.66  0.06  3.52]\n"
     ]
    }
   ],
   "source": [
    "print(gradient(theta_rfe, X_rfe, y_norm))\n",
    "print(gradient(theta_rfe, X_rfe, y_norm, regularized=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimization we will use optimization algorithms of scipy.\n",
    "\n",
    "One can choose between different optimization algorithms.\n",
    "\n",
    "Be aware: when using fmin_tnc the result is an array of arrays, so use result[0], when using fmin_bfgs use result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularized = True\n",
    "learning_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 173.088274\n",
      "         Iterations: 5\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 33\n",
      "[ -1.18096505e-04  -3.44994773e-04  -1.72879490e-04  -6.64984326e-04\n",
      "  -1.05470462e-04  -2.20705087e-05   5.74895762e-05   1.28137491e-04\n",
      "  -2.09161720e-04  -1.56558667e-04  -2.47523970e-04  -3.25374787e-04\n",
      "   2.46408804e-05  -7.08928577e-04   5.55944651e-05   9.49008967e-06\n",
      "   6.83536740e-06  -1.90016268e-04  -1.78646257e-04  -7.03766940e-06\n",
      "   6.75875802e-05   9.14448843e-05  -2.11804019e-04   2.26278877e-06\n",
      "  -1.84577989e-05  -4.39146488e-05  -5.57238982e-05]\n",
      "173.088274498\n"
     ]
    }
   ],
   "source": [
    "#result = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, y_norm))\n",
    "result = opt.fmin_bfgs(cost, theta, fprime=gradient, args=(X, y_norm, regularized, learning_rate))\n",
    "print(result)\n",
    "print(cost(result, X, y_norm, regularized, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 173.090659\n",
      "         Iterations: 3\n",
      "         Function evaluations: 68\n",
      "         Gradient evaluations: 57\n",
      "[ -2.49332787e-04   2.35102867e-06  -3.18916244e-04  -6.02470062e-04\n",
      "  -3.93752809e-04  -4.49009453e-04  -2.23535585e-04  -4.60311800e-04\n",
      "  -2.68279794e-04  -9.75456474e-04]\n",
      "173.090658704\n"
     ]
    }
   ],
   "source": [
    "#result_stable = opt.fmin_tnc(func=cost, x0=theta_stable, fprime=gradient, args=(X_stable, y_norm))\n",
    "result_stable = opt.fmin_bfgs(cost, theta_stable, fprime=gradient, args=(X_stable, y_norm, regularized, learning_rate))\n",
    "print(result_stable)\n",
    "print(cost(result_stable, X_stable , y_norm, regularized, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 173.086742\n",
      "         Iterations: 9\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "[ -8.00426541e-02  -1.15220689e-07   1.51750002e-07  -8.27338971e-07\n",
      "  -4.54580599e-08]\n",
      "173.086741773\n"
     ]
    }
   ],
   "source": [
    "#result_rfe = opt.fmin_tnc(func=cost, x0=theta_rfe, fprime=gradient, args=(X_rfe, y_norm))\n",
    "result_rfe = opt.fmin_bfgs(cost, theta_rfe, fprime=gradient, args=(X_rfe, y_norm, regularized, learning_rate))\n",
    "\n",
    "print(result_rfe)\n",
    "print(cost(result_rfe, X_rfe , y_norm, regularized, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    probability = sigmoid(X * theta.T)\n",
    "    return [1 if x >= 0.5 else 0 for x in probability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(theta, X, y):\n",
    "    theta_min = np.matrix(theta)\n",
    "    predictions = predict(theta_min, X)\n",
    "    correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, y)]\n",
    "    accuracy = (sum(map(int, correct)) % len(correct))\n",
    "    print(theta_min)\n",
    "    print('\\taccuracy = {0}%'.format(accuracy))\n",
    "    print('\\tMAE: ', metrics.mean_absolute_error(y, predictions))\n",
    "    print('\\tMSE: ', metrics.mean_squared_error(y, predictions))\n",
    "    print('\\tRMSE: ', np.sqrt(metrics.mean_squared_error(y, predictions)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9.37973281e-03  -2.06479388e-12  -7.02091099e-10  -3.90822182e-03\n",
      "    8.35503697e-13  -1.98984736e-12  -5.30877864e-10  -3.12657753e-03\n",
      "    5.63498516e-12   4.37301478e-10   9.98572210e-11  -6.25315556e-03\n",
      "    2.23439513e-10  -5.17502487e-03  -8.20726717e-03  -4.29904307e-03\n",
      "   -3.90821801e-04   3.51739922e-03  -6.25315312e-03  -3.12658186e-03\n",
      "    2.16656013e-09  -9.37973304e-03  -3.12657679e-03   3.12657702e-03\n",
      "   -1.52016361e-02   3.23439592e-04   5.49846370e-03]]\n",
      "\taccuracy = 34%\n",
      "\tMAE:  0.37037037037\n",
      "\tMSE:  0.37037037037\n",
      "\tRMSE:  0.60858061945\n",
      "\n",
      "[[ -7.41080028e-02  -5.08273319e-10   4.47159535e-09  -1.39680865e-10\n",
      "    2.47864750e-09  -2.23257567e-11  -3.28825641e-10  -6.23697358e-09\n",
      "    1.70780461e-08   1.20084818e-09]]\n",
      "\taccuracy = 34%\n",
      "\tMAE:  0.37037037037\n",
      "\tMSE:  0.37037037037\n",
      "\tRMSE:  0.60858061945\n",
      "\n",
      "[[ -7.41079539e-02   1.77519375e-08   1.64187546e-08  -7.19493387e-08\n",
      "    1.83461308e-08]]\n",
      "\taccuracy = 34%\n",
      "\tMAE:  0.37037037037\n",
      "\tMSE:  0.37037037037\n",
      "\tRMSE:  0.60858061945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy(result, X_test, y_norm_test)\n",
    "accuracy(result_stable, X_stable_test, y_norm_test)\n",
    "accuracy(result_rfe, X_rfe_test, y_norm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from patsy import dmatrices\n",
    "import statsmodels.discrete.discrete_model as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.324837595542\n",
      "            Iterations: 101\n",
      "            Function evaluations: 113\n",
      "            Gradient evaluations: 101\n",
      "\n",
      "375.420768397\n",
      "[[-0.84062973 -0.02214585  1.75765078  0.06457658  0.03249216  0.0031433\n",
      "  -0.88166603 -0.09067774 -0.01604277  0.60542375  0.38779565 -0.48795636\n",
      "   1.55443697 -0.36073846 -1.19355398  0.40376121 -0.68058341  0.9228331\n",
      "  -0.81988611 -0.13691485  0.0795973  -1.28224555  0.37994929  0.17380751\n",
      "  -1.54053958 -0.4881691   1.37089333]]\n",
      "\taccuracy = 221%\n",
      "\tMAE:  0.116\n",
      "\tMSE:  0.116\n",
      "\tRMSE:  0.340587727319\n",
      "\n",
      "[[-0.84062973 -0.02214585  1.75765078  0.06457658  0.03249216  0.0031433\n",
      "  -0.88166603 -0.09067774 -0.01604277  0.60542375  0.38779565 -0.48795636\n",
      "   1.55443697 -0.36073846 -1.19355398  0.40376121 -0.68058341  0.9228331\n",
      "  -0.81988611 -0.13691485  0.0795973  -1.28224555  0.37994929  0.17380751\n",
      "  -1.54053958 -0.4881691   1.37089333]]\n",
      "\taccuracy = 42%\n",
      "\tMAE:  0.106382978723\n",
      "\tMSE:  0.106382978723\n",
      "\tRMSE:  0.326164036527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(y_norm, X)\n",
    "fit = logit.fit_regularized(method='l1')\n",
    "\n",
    "#print('Intercept + Coefficients: ', fit.params)\n",
    "#print('P-Values: ', fit.pvalues)\n",
    "#print('Conf. Interval: ', fit.conf_int())\n",
    "\n",
    "print('')\n",
    "print(cost(fit.params, X , y_norm))\n",
    "accuracy(fit.params, X, y_norm)\n",
    "accuracy(fit.params, X_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.376469892924\n",
      "            Iterations: 62\n",
      "            Function evaluations: 66\n",
      "            Gradient evaluations: 62\n",
      "\n",
      "315.617591008\n",
      "[[ -1.06665852e+01   9.20137567e-01   1.17984837e+00   1.27079276e+00\n",
      "    7.68490462e-01  -8.36192745e-03   7.76653610e-01   5.58849145e-01\n",
      "    3.08768695e+00   6.58286803e-01]]\n",
      "\taccuracy = 211%\n",
      "\tMAE:  0.156\n",
      "\tMSE:  0.156\n",
      "\tRMSE:  0.394968353163\n",
      "\n",
      "[[ -1.06665852e+01   9.20137567e-01   1.17984837e+00   1.27079276e+00\n",
      "    7.68490462e-01  -8.36192745e-03   7.76653610e-01   5.58849145e-01\n",
      "    3.08768695e+00   6.58286803e-01]]\n",
      "\taccuracy = 42%\n",
      "\tMAE:  0.106382978723\n",
      "\tMSE:  0.106382978723\n",
      "\tRMSE:  0.326164036527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(y_norm, X_stable)\n",
    "fit = logit.fit_regularized(method='l1')\n",
    "\n",
    "#print('Intercept + Coefficients: ', fit.params)\n",
    "#print('P-Values: ', fit.pvalues)\n",
    "#print('Conf. Interval: ', fit.conf_int())\n",
    "\n",
    "print('')\n",
    "print(cost(fit.params, X_stable , y_norm))\n",
    "accuracy(fit.params, X_stable, y_norm)\n",
    "accuracy(fit.params, X_stable_test, y_norm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.430968405179\n",
      "            Iterations: 35\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 35\n",
      "\n",
      "273.282490615\n",
      "[[-0.25236233 -2.06557009  1.43219918  0.15075648  1.20273334]]\n",
      "\taccuracy = 205%\n",
      "\tMAE:  0.18\n",
      "\tMSE:  0.18\n",
      "\tRMSE:  0.424264068712\n",
      "\n",
      "[[-0.25236233 -2.06557009  1.43219918  0.15075648  1.20273334]]\n",
      "\taccuracy = 40%\n",
      "\tMAE:  0.148936170213\n",
      "\tMSE:  0.148936170213\n",
      "\tRMSE:  0.385922492494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(y_norm, X_rfe)\n",
    "fit = logit.fit_regularized(method='l1')\n",
    "\n",
    "#print('Intercept + Coefficients: ', fit.params)\n",
    "#print('P-Values: ', fit.pvalues)\n",
    "#print('Conf. Interval: ', fit.conf_int())\n",
    "\n",
    "print('')\n",
    "print(cost(fit.params, X_rfe , y_norm))\n",
    "accuracy(fit.params, X_rfe, y_norm)\n",
    "accuracy(fit.params, X_rfe_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apospiech/Programme/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "458.843960612\n",
      "[[-0.28042899  0.00388133  0.67266106 -0.14023342 -0.0075521  -0.00776169\n",
      "  -0.42133289  0.29430421 -0.00603242 -0.1628245   0.20971573  0.14356666\n",
      "   0.5522471  -0.03157603  0.07277823 -0.42179075 -0.35623571  0.42481925\n",
      "  -0.63307247  0.41098276 -0.05833927 -0.59824974  0.21164585  0.1061749\n",
      "  -0.49515719  0.04920188  0.16552632]]\n",
      "\taccuracy = 131%\n",
      "\tMAE:  0.476\n",
      "\tMSE:  0.476\n",
      "\tRMSE:  0.689927532426\n",
      "\n",
      "[[-0.28042899  0.00388133  0.67266106 -0.14023342 -0.0075521  -0.00776169\n",
      "  -0.42133289  0.29430421 -0.00603242 -0.1628245   0.20971573  0.14356666\n",
      "   0.5522471  -0.03157603  0.07277823 -0.42179075 -0.35623571  0.42481925\n",
      "  -0.63307247  0.41098276 -0.05833927 -0.59824974  0.21164585  0.1061749\n",
      "  -0.49515719  0.04920188  0.16552632]]\n",
      "\taccuracy = 30%\n",
      "\tMAE:  0.36170212766\n",
      "\tMSE:  0.36170212766\n",
      "\tRMSE:  0.601416767026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C=1.0)\n",
    "\n",
    "fit = model.fit(X.astype('float'), y)\n",
    "\n",
    "#print('Coefficients a1, a2: ', fit.coef_)\n",
    "#print('Intercept a0: ', fit.intercept_)\n",
    "#print('R-Squared: ',fit.score(X_test, y_test))\n",
    "\n",
    "print('')\n",
    "print(cost(fit.coef_[4], X , y_norm))\n",
    "accuracy(fit.coef_[4], X, y_norm)\n",
    "accuracy(fit.coef_[4], X_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "394.58608353\n",
      "[[-0.43802304 -0.53815517  0.49048699 -0.06004878  0.32681596 -0.01593966\n",
      "  -0.080908    0.36411915 -0.83792275 -0.10848884]]\n",
      "\taccuracy = 132%\n",
      "\tMAE:  0.472\n",
      "\tMSE:  0.472\n",
      "\tRMSE:  0.687022561493\n",
      "\n",
      "[[-0.43802304 -0.53815517  0.49048699 -0.06004878  0.32681596 -0.01593966\n",
      "  -0.080908    0.36411915 -0.83792275 -0.10848884]]\n",
      "\taccuracy = 30%\n",
      "\tMAE:  0.36170212766\n",
      "\tMSE:  0.36170212766\n",
      "\tRMSE:  0.601416767026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C=1.0)\n",
    "\n",
    "fit = model.fit(X_stable.astype('float'), y)\n",
    "\n",
    "#print('Coefficients a1, a2: ', fit.coef_)\n",
    "#print('Intercept a0: ', fit.intercept_)\n",
    "#print('R-Squared: ',fit.score(X_test, y_test))\n",
    "\n",
    "print('')\n",
    "print(cost(fit.coef_[4], X_stable , y_norm))\n",
    "accuracy(fit.coef_[4], X_stable, y_norm)\n",
    "accuracy(fit.coef_[4], X_stable_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients a1, a2:  [[ 0.12807423  1.85778541 -1.26769392 -0.03302522 -1.12282545]\n",
      " [-0.58969506 -0.56918995  0.36207895 -0.42036728 -0.14151754]\n",
      " [-1.14977823 -1.24322425  0.62814076 -0.45463305  0.57282815]\n",
      " [-1.16331325 -1.41687772  0.60215368  0.22764883  0.62961401]\n",
      " [-1.51086885 -1.07734909  0.04828364  0.54518447  0.53733416]]\n",
      "\n",
      "256.624011159\n",
      "[[-1.51086885 -1.07734909  0.04828364  0.54518447  0.53733416]]\n",
      "\taccuracy = 139%\n",
      "\tMAE:  0.444\n",
      "\tMSE:  0.444\n",
      "\tRMSE:  0.666333249958\n",
      "\n",
      "[[-1.51086885 -1.07734909  0.04828364  0.54518447  0.53733416]]\n",
      "\taccuracy = 31%\n",
      "\tMAE:  0.340425531915\n",
      "\tMSE:  0.340425531915\n",
      "\tRMSE:  0.583459965992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C=1.0)\n",
    "\n",
    "fit = model.fit(X_rfe, y)\n",
    "\n",
    "print('Coefficients a1, a2: ', fit.coef_)\n",
    "#print('Intercept a0: ', fit.intercept_)\n",
    "#print('R-Squared: ',fit.score(X_test, y_test))\n",
    "\n",
    "print('')\n",
    "print(cost(fit.coef_[4], X_rfe , y_norm))\n",
    "accuracy(fit.coef_[4], X_rfe, y_norm)\n",
    "accuracy(fit.coef_[4], X_rfe_test, y_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "see Manual Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "\n",
    "## Overviews:\n",
    "\n",
    "http://wiki.fast.ai/index.php/Logistic_Regression\n",
    "\n",
    "http://www.holehouse.org/mlclass/06_Logistic_Regression.html\n",
    "\n",
    "https://www.cs.cmu.edu/~ninamf/courses/601sp15/lectures.shtml\n",
    "\n",
    "https://aimotion.blogspot.de/2011/11/machine-learning-with-python-logistic.html\n",
    "\n",
    "## Notebooks:\n",
    "\n",
    "https://github.com/stephengo/heart-disease-model/blob/master/LogRegression.ipynb\n",
    "\n",
    "https://github.com/LucDemortier/HeartDiseaseStudy/blob/master/HeartDiseaseProject.ipynb\n",
    "\n",
    "https://nbviewer.jupyter.org/github/jdwittenauer/ipython-notebooks/blob/master/notebooks/ml/ML-Exercise2.ipynb\n",
    "\n",
    "https://gist.github.com/vietjtnguyen/6655020 - for the manual part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "322px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "940px",
    "left": "0px",
    "right": "1641px",
    "top": "107px",
    "width": "277px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
